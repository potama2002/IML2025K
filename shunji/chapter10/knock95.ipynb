{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BODtcYXYkvcd",
        "outputId": "d3aa6119-7e6e-430a-9478-06942cd55190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhX1c7iwnNoP",
        "outputId": "aa745212-c24d-4a92-f5ea-e0ea0803f8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n",
            "mkdir: cannot create directory ‘./subword’: File exists\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab\\ Notebooks\n",
        "%mkdir ./subword"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX6SITFrl65I"
      },
      "source": [
        "# BPE (Bite Pair Encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI990vERkRS9",
        "outputId": "5f08b9b1-095d-4465-af07-b4ae9b61241b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting subword-nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from subword-nmt) (4.64.0)\n",
            "Installing collected packages: mock, subword-nmt\n",
            "Successfully installed mock-4.0.3 subword-nmt-0.3.8\n"
          ]
        }
      ],
      "source": [
        "!pip install subword-nmt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ_JV0mtk4Mg",
        "outputId": "4b186265-9119-4c43-d0e3-d6f42d304e68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 16000/16000 [00:35<00:00, 444.76it/s]\n"
          ]
        }
      ],
      "source": [
        "!subword-nmt learn-bpe -s 16000 < ./tokenized_data/train.ja > ./subword/train_ja_code.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCOd2BTorDai",
        "outputId": "6eda1f80-c349-4439-e295-fe3922c2ab5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16001 ./subword/train_ja_code.txt\n"
          ]
        }
      ],
      "source": [
        "!wc -l ./subword/train_ja_code.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRhmh2zzsSR3"
      },
      "outputs": [],
      "source": [
        "!subword-nmt apply-bpe -c ./subword/train_ja_code.txt < ./tokenized_data/train.ja > ./subword/train.ja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8XPquFVsrcS",
        "outputId": "9a3274d6-cd5d-4680-bdc5-2c7a017b51b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "せっ@@ しゅう 、 14@@ 20 年 （ 応永 27 年 ） - 1506 年 （ 永 正 3 年 ） ） は 号 で 、 15 世紀 後半 室町 時代 に 活躍 し た 水墨 画家 ・ 禅僧 で 、 画@@ 聖 と も 称え られる 。 \n",
            "日本 の 水墨 画 を 一変 さ せ た 。 \n",
            "諱 は 「 等 楊 （ とう よう ） 」 、 もしくは 「 拙 宗 （ せっ@@ しゅう ） 」 と 号 し た 。 \n",
            "備中 国 に 生まれ 、 京都 ・ 相国寺 に 入っ て から 周防 国 に 移る 。 \n",
            "その後 遣 明 使 に 随行 し て 中国 （ 明 ） に 渡っ て 中国 の 水墨 画 を 学ん だ 。 \n",
            "作品 は 数多く 、 中国 風 の 山水 画 だけ で なく 人物 画 や 花鳥 画 も よく し た 。 \n",
            "大胆 な 構図 と 力@@ 強い 筆 線 は 非常 に 個性 的 な 画風 を 作り出し て いる 。 \n",
            "現存 する 作品 の うち 6 点 が 国宝 に 指定 さ れ て おり 、 日本 の 画家 の なか でも 別格 の 評価 を 受け て いる と いえる 。 \n",
            "この ため 、 花鳥 図 屏風 など に 「 伝 雪舟 筆 」 さ れる 作品 は 大変 多い 。 \n",
            "真@@ 筆 で ある か 専門 家 の 間 で も 意見 の 分かれる もの も 多々 ある 。 \n"
          ]
        }
      ],
      "source": [
        "!head -n 10 ./subword/train.ja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6Ki8QV5tEMK"
      },
      "outputs": [],
      "source": [
        "# !wc -w ./tokenized_data/train.ja\n",
        "# !wc -w ./subword/train.ja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xF2yXYcusof",
        "outputId": "e9ededde-a28e-40aa-a62b-6c0e77b3bea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 12% 1979/16000 [00:01<00:10, 1340.21it/s]no pair has frequency >= 2. Stopping\n",
            " 13% 2072/16000 [00:01<00:11, 1230.42it/s]\n",
            " 12% 1983/16000 [00:01<00:10, 1341.79it/s]no pair has frequency >= 2. Stopping\n",
            " 13% 2083/16000 [00:01<00:11, 1235.04it/s]\n"
          ]
        }
      ],
      "source": [
        "!subword-nmt learn-bpe -s 16000 < ./tokenized_data/dev.ja > ./subword/dev_ja_code.txt\n",
        "!subword-nmt apply-bpe -c ./subword/dev_ja_code.txt < ./tokenized_data/dev.ja > ./subword/dev.ja\n",
        "\n",
        "!subword-nmt learn-bpe -s 16000 < ./tokenized_data/test.ja > ./subword/test_ja_code.txt\n",
        "!subword-nmt apply-bpe -c ./subword/test_ja_code.txt < ./tokenized_data/test.ja > ./subword/test.ja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On5iTozdtSyX",
        "outputId": "07398f26-5d2d-4cd5-c668-e6613bcce170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 16000/16000 [00:27<00:00, 574.08it/s]\n",
            " 22% 3506/16000 [00:02<00:04, 2630.20it/s]no pair has frequency >= 2. Stopping\n",
            " 25% 3985/16000 [00:02<00:06, 1776.25it/s]\n",
            " 25% 3971/16000 [00:02<00:03, 3196.99it/s]no pair has frequency >= 2. Stopping\n",
            " 26% 4156/16000 [00:02<00:06, 1731.94it/s]\n"
          ]
        }
      ],
      "source": [
        "!subword-nmt learn-bpe -s 16000 < ./tokenized_data/train.en > ./subword/train_en_code.txt\n",
        "!subword-nmt apply-bpe -c ./subword/train_en_code.txt < ./tokenized_data/train.en > ./subword/train.en\n",
        "\n",
        "!subword-nmt learn-bpe -s 16000 < ./tokenized_data/dev.en > ./subword/dev_en_code.txt\n",
        "!subword-nmt apply-bpe -c ./subword/dev_en_code.txt < ./tokenized_data/dev.en > ./subword/dev.en\n",
        "\n",
        "!subword-nmt learn-bpe -s 16000 < ./tokenized_data/test.en > ./subword/test_en_code.txt\n",
        "!subword-nmt apply-bpe -c ./subword/test_en_code.txt < ./tokenized_data/test.en > ./subword/test.en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rqdJGqymGlT"
      },
      "source": [
        "# SentencePiece\n",
        "BPEでは単語分割する必要があるため，日本語や中国語のような単語分割(スペース分割)が難しい言語では正確さに疑問が残る．→SentencePiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6nqouFtkFhI",
        "outputId": "b5d4c866-1d5c-4c56-9de2-1ce63b674fc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 34.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qb57E15xkLLb"
      },
      "outputs": [],
      "source": [
        "import sentencepiece as spm\n",
        "import re\n",
        "\n",
        "spm.SentencePieceTrainer.Train('--input=kftt-data-1.0/data/orig/kyoto-train.ja --model_prefix=kyoto_ja --vocab_size=16000 --character_coverage=1.0')\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load('kyoto_ja.model')\n",
        "\n",
        "for src, dst in [\n",
        "    ('kftt-data-1.0/data/orig/kyoto-train.ja', './subword/train.ja'),\n",
        "    ('kftt-data-1.0/data/orig/kyoto-dev.ja', './subword/dev.ja'),\n",
        "    ('kftt-data-1.0/data/orig/kyoto-test.ja', './subword/test.ja'),\n",
        "]:\n",
        "    with open(src, 'r') as rf, open(dst, 'w') as wf:\n",
        "        for x in rf:\n",
        "            x = x.strip()\n",
        "            x = re.sub(r'\\s+', ' ', x)\n",
        "            x = sp.encode_as_pieces(x)\n",
        "            x = ' '.join(x)\n",
        "            print(x, file=wf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcigtuKzvlar"
      },
      "source": [
        "# 91-94の手順"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxI2w5XLvssn",
        "outputId": "2f924dbc-915d-4e78-81f3-303c4b7d8855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'fairseq' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/Colab Notebooks/fairseq\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/drive/MyDrive/Colab%20Notebooks/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (0.29.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (4.64.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (2022.6.2)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 14.5 MB/s \n",
            "\u001b[?25hCollecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (1.12.0+cu113)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 13.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==0.12.2) (1.15.1)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 68.7 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2) (5.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.1.1)\n",
            "Collecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.8.10)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==0.12.2) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==0.12.2) (3.8.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=3584acb712775d65aae2ee26648b5cede6118e087334355f4e09c1f8c2f54464\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, bitarray, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 bitarray-2.6.0 colorama-0.4.5 fairseq hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.5.1 sacrebleu-2.1.0\n",
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd fairseq \n",
        "!pip install --editable ./\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xd7dFHhv8rq",
        "outputId": "19a22bfa-1363-4fbf-d40e-21e35154bd4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/env/python\n",
            "/env/python:/content/drive/MyDrive/Colab Notebooks/fairseq/\n"
          ]
        }
      ],
      "source": [
        "!echo $PYTHONPATH\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/drive/MyDrive/Colab Notebooks/fairseq/\"\n",
        "\n",
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg9R2yNjv_Ow",
        "outputId": "ad85e7cb-98b3-4ca6-8625-37a087472ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-22 03:28:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-07-22 03:28:12 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='result/preprocessing_subword_sp', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, simul_type=None, source_lang='ja', srcdict=None, suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref='./subword/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=3, thresholdtgt=3, tokenizer='space', tpu=False, trainpref='./subword/train', use_plasma_view=False, user_dir=None, validpref='./subword/dev', wandb_project=None, workers=20)\n",
            "2022-07-22 03:29:26 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 14848 types\n",
            "2022-07-22 03:30:48 | INFO | fairseq_cli.preprocess | [ja] ./subword/train.ja: 440288 sents, 10735573 tokens, 0.0143% replaced (by <unk>)\n",
            "2022-07-22 03:30:48 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 14848 types\n",
            "2022-07-22 03:30:49 | INFO | fairseq_cli.preprocess | [ja] ./subword/dev.ja: 1166 sents, 24825 tokens, 0.0201% replaced (by <unk>)\n",
            "2022-07-22 03:30:49 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 14848 types\n",
            "2022-07-22 03:30:50 | INFO | fairseq_cli.preprocess | [ja] ./subword/test.ja: 1160 sents, 26821 tokens, 0.0149% replaced (by <unk>)\n",
            "2022-07-22 03:30:50 | INFO | fairseq_cli.preprocess | [en] Dictionary: 18752 types\n",
            "2022-07-22 03:31:42 | INFO | fairseq_cli.preprocess | [en] ./subword/train.en: 440288 sents, 11457979 tokens, 0.0298% replaced (by <unk>)\n",
            "2022-07-22 03:31:42 | INFO | fairseq_cli.preprocess | [en] Dictionary: 18752 types\n",
            "2022-07-22 03:31:44 | INFO | fairseq_cli.preprocess | [en] ./subword/dev.en: 1166 sents, 25511 tokens, 3.93% replaced (by <unk>)\n",
            "2022-07-22 03:31:44 | INFO | fairseq_cli.preprocess | [en] Dictionary: 18752 types\n",
            "2022-07-22 03:31:45 | INFO | fairseq_cli.preprocess | [en] ./subword/test.en: 1160 sents, 26997 tokens, 3.7% replaced (by <unk>)\n",
            "2022-07-22 03:31:45 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to result/preprocessing_subword_sp\n"
          ]
        }
      ],
      "source": [
        "!fairseq-preprocess \\\n",
        "    --trainpref ./subword/train \\\n",
        "    --validpref ./subword/dev \\\n",
        "    --testpref  ./subword/test \\\n",
        "    --source-lang ja \\\n",
        "    --target-lang en \\\n",
        "    --tokenizer space \\\n",
        "    --workers 20 \\\n",
        "    --thresholdsrc 3\\\n",
        "    --thresholdtgt 3\\\n",
        "    --task translation \\\n",
        "    --destdir result/preprocessing_subword_sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ61UY7YwNaw",
        "outputId": "b7003b54-839b-47ef-d3cc-41a9e69f1507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "2022-07-22 03:31:47 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2022-07-22 03:31:50 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'log96', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 256, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 256, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 6, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'result/train_subword', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 6, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer', activation_dropout=0.0, activation_fn='relu', adam_betas=(0.9, 0.999), adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer', attention_dropout=0.0, azureml_logging=False, batch_size=256, batch_size_valid=256, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='result/preprocessing_subword', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.0, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0001], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=6, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='result/train_subword', save_interval=6, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, simul_type=None, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir='log96', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=0, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'result/preprocessing_subword', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.0, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2022-07-22 03:31:51 | INFO | fairseq.tasks.translation | [ja] dictionary: 23936 types\n",
            "2022-07-22 03:31:51 | INFO | fairseq.tasks.translation | [en] dictionary: 18752 types\n",
            "2022-07-22 03:31:53 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(23936, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayerBase(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoderBase(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(18752, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=512, out_features=18752, bias=False)\n",
            "  )\n",
            ")\n",
            "2022-07-22 03:31:53 | INFO | fairseq_cli.train | task: TranslationTask\n",
            "2022-07-22 03:31:53 | INFO | fairseq_cli.train | model: TransformerModel\n",
            "2022-07-22 03:31:53 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2022-07-22 03:31:53 | INFO | fairseq_cli.train | num. shared model params: 94,497,792 (num. trained: 94,497,792)\n",
            "2022-07-22 03:31:53 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2022-07-22 03:31:54 | INFO | fairseq.data.data_utils | loaded 1,166 examples from: result/preprocessing_subword/valid.ja-en.ja\n",
            "2022-07-22 03:31:56 | INFO | fairseq.data.data_utils | loaded 1,166 examples from: result/preprocessing_subword/valid.ja-en.en\n",
            "2022-07-22 03:31:56 | INFO | fairseq.tasks.translation | result/preprocessing_subword valid ja-en 1166 examples\n",
            "2022-07-22 03:32:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-07-22 03:32:00 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n",
            "2022-07-22 03:32:00 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2022-07-22 03:32:00 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2022-07-22 03:32:00 | INFO | fairseq_cli.train | max tokens per device = None and max sentences per device = 256\n",
            "2022-07-22 03:32:00 | INFO | fairseq.trainer | Preparing to load checkpoint result/train_subword/checkpoint_last.pt\n",
            "2022-07-22 03:32:25 | INFO | fairseq.trainer | Loaded checkpoint result/train_subword/checkpoint_last.pt (epoch 7 @ 9875 updates)\n",
            "2022-07-22 03:32:25 | INFO | fairseq.trainer | loading train data for epoch 7\n",
            "2022-07-22 03:32:30 | INFO | fairseq.data.data_utils | loaded 440,288 examples from: result/preprocessing_subword/train.ja-en.ja\n",
            "2022-07-22 03:32:34 | INFO | fairseq.data.data_utils | loaded 440,288 examples from: result/preprocessing_subword/train.ja-en.en\n",
            "2022-07-22 03:32:34 | INFO | fairseq.tasks.translation | result/preprocessing_subword train ja-en 440288 examples\n",
            "2022-07-22 03:32:35 | INFO | fairseq_cli.train | done training in 0.0 seconds\n"
          ]
        }
      ],
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0 \n",
        "!fairseq-train result/preprocessing_subword \\\n",
        "    --fp16 \\\n",
        "    --save-dir result/train_subword \\\n",
        "    --max-epoch 6 \\\n",
        "    --arch transformer \\\n",
        "    --optimizer adam \\\n",
        "    --lr 1e-4 \\\n",
        "    --weight-decay 0.0001 \\\n",
        "    --criterion label_smoothed_cross_entropy \\\n",
        "    --batch-size 256 \\\n",
        "    --save-interval 6 \\\n",
        "    --tensorboard-logdir log96 \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DWXYc0LwZS0",
        "outputId": "048ea37b-e5b4-4e80-e8b0-5eddf75cefe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsoYeNi1wcku",
        "outputId": "7f2a73d0-4c11-4715-a5e0-9533db3529b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-22 03:34:34 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'result/train_subword/checkpoint_last.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 1, 'input': '-'}, 'model': None, 'task': {'_name': 'translation', 'data': 'result/preprocessing_subword', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2022-07-22 03:34:34 | INFO | fairseq.tasks.translation | [ja] dictionary: 23936 types\n",
            "2022-07-22 03:34:34 | INFO | fairseq.tasks.translation | [en] dictionary: 18752 types\n",
            "2022-07-22 03:34:34 | INFO | fairseq_cli.interactive | loading model(s) from result/train_subword/checkpoint_last.pt\n",
            "2022-07-22 03:34:39 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-07-22 03:34:39 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/bin/fairseq-interactive\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-interactive')())\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq_cli/interactive.py\", line 313, in cli_main\n",
            "    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq_cli/interactive.py\", line 228, in main\n",
            "    generator, models, sample, constraints=constraints\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq/tasks/fairseq_task.py\", line 543, in inference_step\n",
            "    models, sample, prefix_tokens=prefix_tokens, constraints=constraints\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq/sequence_generator.py\", line 204, in generate\n",
            "    return self._generate(sample, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq/sequence_generator.py\", line 424, in _generate\n",
            "    original_batch_idxs,\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq/search.py\", line 141, in step\n",
            "    indices_buf = indices_buf.fmod(vocab_size)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!fairseq-interactive --path result/train_subword/checkpoint_last.pt result/preprocessing_subword < ./subword/test.ja | grep '^H' | cut -f3 > 95.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13usJBoxwrJK",
        "outputId": "91bb50c4-0bb7-4dca-f10e-303ccf0cd405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(ignore_case=False, order=4, ref='./subword/test.en', sacrebleu=False, sentence_bleu=False, sys='95.out')\n",
            "BLEU4 = 4.32, 30.6/10.2/2.9/1.2 (BP=0.758, ratio=0.783, syslen=1570, reflen=2005)\n"
          ]
        }
      ],
      "source": [
        "!fairseq-score \\\n",
        "--sys 95.out \\\n",
        "--ref ./subword/test.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCzuUUqRw0MS"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "for N in `seq 1 5`\n",
        "do\n",
        "    fairseq-interactive --path result/train_subword/checkpoint_last.pt --beam $N result/preprocessing_subword < ./subword/test.ja | grep '^H' | cut -f3 > 95_beam$N.out\n",
        "done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mN7Ge1y1C6_",
        "outputId": "a60220b8-5b51-4d77-e1a8-aa043dc7d1fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/bin/fairseq-score\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-score')())\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq_cli/score.py\", line 98, in cli_main\n",
            "    score(f)\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq_cli/score.py\", line 92, in score\n",
            "    print(scorer.result_string(args.order))\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq/scoring/bleu.py\", line 162, in result_string\n",
            "    self.score(order=order),\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq/scoring/bleu.py\", line 136, in score\n",
            "    return self.brevity() * math.exp(psum / order) * 100\n",
            "  File \"/content/drive/MyDrive/Colab Notebooks/fairseq/fairseq/scoring/bleu.py\", line 150, in brevity\n",
            "    r = self.stat.reflen / self.stat.predlen\n",
            "ZeroDivisionError: division by zero\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "for N in `seq 1 5`\n",
        "do\n",
        "    fairseq-score --sys 95_beam$N.out --ref ./subword/test.en > 95_beam$N.score\n",
        "done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9TU0IvmxHep",
        "outputId": "c56d5d0d-41a1-4c15-a73c-c94fa5b5d769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(ignore_case=False, order=4, ref='./subword/test.en', sacrebleu=False, sentence_bleu=False, sys='95_beam5.out')\n",
            "BLEU4 = 2.02, 20.3/4.4/1.2/0.4 (BP=0.777, ratio=0.798, syslen=20621, reflen=25836)\n"
          ]
        }
      ],
      "source": [
        "!cat 95_beam5.score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5p3_oQ45xQ-L",
        "outputId": "a6b7701c-0c3c-49b5-a7ea-f0fd3e9ba794"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "\n",
        "def read_score(filename):\n",
        "    with open(filename) as f:\n",
        "        x = f.readlines()[1]\n",
        "        x = re.search(r'(?<=BLEU4 = )\\d*\\.\\d*(?=,)', x)\n",
        "        return float(x.group())\n",
        "\n",
        "xs = range(1, 6)\n",
        "ys = [read_score(f'95_beam{x}.score') for x in xs]\n",
        "plt.plot(xs, ys)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foJsVMgynrpp"
      },
      "source": [
        "# 96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "HmhfGtBb1bvU",
        "outputId": "8a03fb44-8003-4522-9d33-b0d75ce0279c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir log96"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "knock95.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "e63aa626c3c030918726870aae77b3d3193589f868c9f7283f19d8a6631c5547"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
